{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities \n",
    "\n",
    "First, we defined all common imports and functions used across the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "snapshots = []\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    print(f\"\\tReading file: {file_path}\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def calculate_average(data):\n",
    "    return sum(data) / len(data)\n",
    "    \n",
    "def get_snapshots():\n",
    "    if len(snapshots) > 0:\n",
    "        print(\"Returning existing snapshots\")\n",
    "        return snapshots\n",
    "\n",
    "    print(\"Returning snapshots from OS\")\n",
    "    for root, _, files in os.walk(\"../snapshots\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                snapshots.append(read_json_file(file_path))\n",
    "    \n",
    "    return snapshots\n",
    "    \n",
    "def draw_pie_chart(sizes, labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "    ax.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question 1\n",
    "\n",
    "What is the typical structure of conversations between developers and ChatGPT?   \n",
    "How many turns does it take on average to reach a conclusion?\n",
    "\n",
    "# Approach 1: Simple Issues Categorization\n",
    "\n",
    "In this approach, .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_conversation(prompt, answer):\n",
    "    prompt = prompt.lower()\n",
    "    answer = answer.lower()\n",
    "\n",
    "    if \"bug\" in prompt or \"error\" in answer:\n",
    "        category = \"Bug\"\n",
    "    elif \"feature\" in prompt or \"implement\" in answer:\n",
    "        category = \"Feature Request\"\n",
    "    elif \"how to\" in prompt or \"why\" in answer:\n",
    "        category = \"Theoretical Question\"\n",
    "    else:\n",
    "        category = \"Other\"\n",
    "\n",
    "    return category\n",
    "\n",
    "\n",
    "def process_json_files_rq1_simple():\n",
    "    categories_count = {\n",
    "        \"Bug\": 0,\n",
    "        \"Feature Request\": 0,\n",
    "        \"Theoretical Question\": 0,\n",
    "        \"Other\": 0,\n",
    "    }\n",
    "\n",
    "    for data in get_snapshots():\n",
    "        for source in data.get(\"Sources\", []):\n",
    "            chatgpt_sharing = source.get(\"ChatgptSharing\", [])\n",
    "            for sharing in chatgpt_sharing:\n",
    "                for conversation in sharing.get(\"Conversations\", []):\n",
    "                    prompt = conversation.get(\"Prompt\", \"\")\n",
    "                    answer = conversation.get(\"Answer\", \"\")\n",
    "                    category = categorize_conversation(prompt, answer)\n",
    "                    categories_count[category] += 1\n",
    "\n",
    "    return categories_count\n",
    "\n",
    "\n",
    "print(\"Starting analysis...\")\n",
    "result_rq1_simple = process_json_files_rq1_simple()\n",
    "print(\"\\nAnalysis completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1 Results: Simple Issues Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results:\")\n",
    "print(\"\\tTotal conversations:\", sum(result_rq1_simple.values()))\n",
    "\n",
    "for category, count in result_rq1_simple.items():\n",
    "    print(f\"\\t{category}: {count}\")\n",
    "\n",
    "draw_pie_chart(\n",
    "    result_rq1_simple.values(), \n",
    "    result_rq1_simple.keys(), \n",
    "    \"Results of RQ1: Simple Issue Categorization\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Issues categorization via Trained Model\n",
    "\n",
    "In this approach, we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Training model complete.\n",
      "\n",
      "Starting analysis...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kdool\\Desktop\\LOG6307E_Final_Project\\src\\main.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kdool/Desktop/LOG6307E_Final_Project/src/main.ipynb#X10sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m train_model()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kdool/Desktop/LOG6307E_Final_Project/src/main.ipynb#X10sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStarting analysis...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kdool/Desktop/LOG6307E_Final_Project/src/main.ipynb#X10sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m model_categories_count, model_categorized_results \u001b[39m=\u001b[39m process_json_files_rq1_model(model, vectorizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kdool/Desktop/LOG6307E_Final_Project/src/main.ipynb#X10sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAnalysis completed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "model = MultinomialNB()\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    # Load and prepare the machine learning model\n",
    "    print(\"Training model...\")\n",
    "    \n",
    "    df = pd.read_csv(\"training_set.csv\")\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        df[\"text\"], df[\"label\"], test_size=0.2, random_state=42\n",
    "    )\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    print(\"Training model complete.\\n\")\n",
    "\n",
    "\n",
    "def combined_categorization(prompt, answer, model, vectorizer):\n",
    "    combined_text = prompt + \" \" + answer\n",
    "    transformed_text = vectorizer.transform([combined_text])\n",
    "    return model.predict(transformed_text)[0]\n",
    "\n",
    "\n",
    "def process_json_files_rq1_model(model, vectorizer):\n",
    "    categories_count = {\n",
    "        \"Bug\": 0,\n",
    "        \"Feature Request\": 0,\n",
    "        \"Theoretical Question\": 0,\n",
    "        \"Other\": 0,\n",
    "    }\n",
    "    results = []\n",
    "\n",
    "    for data in get_snapshots():\n",
    "        for source in data.get(\"Sources\", []):\n",
    "            chatgpt_sharing = source.get(\"ChatgptSharing\", [])\n",
    "            for sharing in chatgpt_sharing:\n",
    "                for conversation in sharing.get(\"Conversations\", []):\n",
    "                    prompt = conversation.get(\"Prompt\", \"\")\n",
    "                    answer = conversation.get(\"Answer\", \"\")\n",
    "                    category = combined_categorization(\n",
    "                        prompt, answer, model, vectorizer\n",
    "                    )\n",
    "                    categories_count[category] += 1\n",
    "\n",
    "                    # Only add to results if category is not 'Other'\n",
    "                    if category != \"Other\":\n",
    "                        results.append(\n",
    "                            {\n",
    "                                \"prompt\": prompt,\n",
    "                                \"answer\": answer,\n",
    "                                \"category\": category,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return categories_count, results\n",
    "\n",
    "\n",
    "train_model()\n",
    "\n",
    "print(\"Starting analysis...\")\n",
    "model_categories_count, model_categorized_results = process_json_files_rq1_model(model, vectorizer)\n",
    "print(\"\\nAnalysis completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1 Results: Issues Categorization via Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results:\")\n",
    "print(\"\\tTotal conversations:\", len(model_categorized_results))\n",
    "\n",
    "for category, count in model_categories_count.items():\n",
    "    print(f\"\\t{category}: {count}\")\n",
    "\n",
    "draw_pie_chart(\n",
    "    model_categories_count.values(), \n",
    "    model_categories_count.keys(), \n",
    "    \"Results of RQ1: Issues Categorization via Trained Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question 2\n",
    "\n",
    "What is the typical structure of conversations between developers and ChatGPT?   \n",
    "How many turns does it take on average to reach a conclusion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_files_rq2():\n",
    "    structure = {\n",
    "        \"NumberOfPrompts\": [],\n",
    "        \"TokensOfPrompts\": [],\n",
    "        \"TokensOfAnswers\": [],\n",
    "        \"ListOfCode\": 0,\n",
    "        \"TotalConversations\": 0,\n",
    "    }\n",
    "  \n",
    "    for data in get_snapshots():\n",
    "        for source in data.get(\"Sources\", []):\n",
    "            chatgpt_sharing = source.get(\"ChatgptSharing\", [])\n",
    "            for sharing in chatgpt_sharing:\n",
    "                \n",
    "                number_of_prompts = sharing.get(\"NumberOfPrompts\")\n",
    "                if number_of_prompts is not None or \"\":\n",
    "                    structure[\"NumberOfPrompts\"].append(number_of_prompts)\n",
    "\n",
    "                number_of_tokens_per_prompts = sharing.get(\"TokensOfPrompts\")\n",
    "                if number_of_tokens_per_prompts is not None or \"\":\n",
    "                    structure[\"TokensOfPrompts\"].append(\n",
    "                        number_of_tokens_per_prompts\n",
    "                    )\n",
    "\n",
    "                number_of_tokens_per_answers = sharing.get(\"TokensOfAnswers\")\n",
    "                if number_of_tokens_per_answers is not None or \"\":\n",
    "                    structure[\"TokensOfAnswers\"].append(\n",
    "                        number_of_tokens_per_answers\n",
    "                    )\n",
    "\n",
    "                # Get number of conversations having code\n",
    "                for conversation in sharing.get(\"Conversations\", []):\n",
    "                    structure[\"TotalConversations\"] += 1\n",
    "                    list_of_code = conversation.get(\"ListOfCode\", [])\n",
    "                    if len(list_of_code) > 0:\n",
    "                        structure[\"ListOfCode\"] += 1\n",
    "\n",
    "    return structure\n",
    "\n",
    "\n",
    "print(\"Starting analysis...\")\n",
    "structure_results = process_json_files_rq2()\n",
    "print(\"\\nAnalysis completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ2 Results: Structure and statistics of conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results:\")\n",
    "\n",
    "print(\"\\tNumber of total conversations: \", structure_results[\"TotalConversations\"])\n",
    "print(\"\\tNumber of conversations having code: \", structure_results[\"ListOfCode\"])\n",
    "\n",
    "print(\n",
    "    \"\\tAverage number of prompts in a conversations: \",\n",
    "    calculate_average(structure_results[\"NumberOfPrompts\"]),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\tAverage number of words in a question of a conversation: \",\n",
    "    calculate_average(structure_results[\"TokensOfPrompts\"]),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\tAverage number of words in an answer of a conversation: \",\n",
    "    calculate_average(structure_results[\"TokensOfAnswers\"]),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
