{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities \n",
    "\n",
    "First, we defined all common imports and functions used across the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "snapshots = []\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    print(f\"\\tReading file: {file_path}\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def calculate_average(data):\n",
    "    return sum(data) / len(data)\n",
    "    \n",
    "def get_snapshots():\n",
    "    if len(snapshots) > 0:\n",
    "        print(\"Returning existing snapshots\")\n",
    "        return snapshots\n",
    "\n",
    "    print(\"Returning snapshots from OS\")\n",
    "    for root, _, files in os.walk(\"../snapshots\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                snapshots.append(read_json_file(file_path))\n",
    "    \n",
    "    return snapshots\n",
    "    \n",
    "def draw_pie_chart(sizes, labels, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "    ax.axis('equal')  # Equal aspect ratio ensures the pie chart is circular.\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question 1\n",
    "\n",
    "What is the typical structure of conversations between developers and ChatGPT?   \n",
    "How many turns does it take on average to reach a conclusion?\n",
    "\n",
    "# Approach 1: Simple Issues Categorization\n",
    "\n",
    "In this approach, .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_conversation(prompt, answer):\n",
    "    prompt = prompt.lower()\n",
    "    answer = answer.lower()\n",
    "\n",
    "    if \"bug\" in prompt or \"error\" in answer:\n",
    "        category = \"Bug\"\n",
    "    elif \"feature\" in prompt or \"implement\" in answer:\n",
    "        category = \"Feature Request\"\n",
    "    elif \"how to\" in prompt or \"why\" in answer:\n",
    "        category = \"Theoretical Question\"\n",
    "    else:\n",
    "        category = \"Other\"\n",
    "\n",
    "    return category\n",
    "\n",
    "\n",
    "def process_json_files_rq1_simple():\n",
    "    categories_count = {\n",
    "        \"Bug\": 0,\n",
    "        \"Feature Request\": 0,\n",
    "        \"Theoretical Question\": 0,\n",
    "        \"Other\": 0,\n",
    "    }\n",
    "\n",
    "    for data in get_snapshots():\n",
    "        for source in data.get(\"Sources\", []):\n",
    "            chatgpt_sharing = source.get(\"ChatgptSharing\", [])\n",
    "            for sharing in chatgpt_sharing:\n",
    "                for conversation in sharing.get(\"Conversations\", []):\n",
    "                    prompt = conversation.get(\"Prompt\", \"\")\n",
    "                    answer = conversation.get(\"Answer\", \"\")\n",
    "                    category = categorize_conversation(prompt, answer)\n",
    "                    categories_count[category] += 1\n",
    "\n",
    "    return categories_count\n",
    "\n",
    "\n",
    "print(\"Starting analysis...\")\n",
    "result_rq1_simple = process_json_files_rq1_simple()\n",
    "print(\"\\nAnalysis completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1 Results: Simple Issues Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results:\")\n",
    "print(\"\\tTotal conversations:\", sum(result_rq1_simple.values()))\n",
    "\n",
    "for category, count in result_rq1_simple.items():\n",
    "    print(f\"\\t{category}: {count}\")\n",
    "\n",
    "draw_pie_chart(\n",
    "    result_rq1_simple.values(), \n",
    "    result_rq1_simple.keys(), \n",
    "    \"Results of RQ1: Simple Issue Categorization\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Issues categorization via Trained Model\n",
    "\n",
    "In this approach, we "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the machine learning model\n",
    "print(\"Training model...\")\n",
    "df = pd.read_csv(\"training_set.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"], df[\"label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "print(\"Training model complete.\\n\")\n",
    "\n",
    "\n",
    "def combined_categorization(prompt, answer, model, vectorizer):\n",
    "    combined_text = prompt + \" \" + answer\n",
    "    transformed_text = vectorizer.transform([combined_text])\n",
    "    return model.predict(transformed_text)[0]\n",
    "\n",
    "def process_json_files_rq1_model(model, vectorizer):\n",
    "    categories_count = {\n",
    "        \"Bug\": 0,\n",
    "        \"Feature Request\": 0,\n",
    "        \"Theoretical Question\": 0,\n",
    "        \"Other\": 0,\n",
    "    }\n",
    "    results = []\n",
    "\n",
    "    for data in get_snapshots():\n",
    "        for source in data.get(\"Sources\", []):\n",
    "            chatgpt_sharing = source.get(\"ChatgptSharing\", [])\n",
    "            for sharing in chatgpt_sharing:\n",
    "                for conversation in sharing.get(\"Conversations\", []):\n",
    "                    prompt = conversation.get(\"Prompt\", \"\")\n",
    "                    answer = conversation.get(\"Answer\", \"\")\n",
    "                    category = combined_categorization(\n",
    "                        prompt, answer, model, vectorizer\n",
    "                    )\n",
    "                    categories_count[category] += 1\n",
    "\n",
    "                    # Only add to results if category is not 'Other'\n",
    "                    if category != \"Other\":\n",
    "                        results.append(\n",
    "                            {\n",
    "                                \"prompt\": prompt,\n",
    "                                \"answer\": answer,\n",
    "                                \"category\": category,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return categories_count, results\n",
    "\n",
    "\n",
    "print(\"Starting analysis...\")\n",
    "model_categories_count, model_categorized_results = process_json_files_rq1_model(model, vectorizer)\n",
    "print(\"\\nAnalysis completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ1 Results: Issues Categorization via Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results:\")\n",
    "print(\"\\tTotal conversations:\", len(model_categorized_results))\n",
    "\n",
    "for category, count in model_categories_count.items():\n",
    "    print(f\"\\t{category}: {count}\")\n",
    "\n",
    "draw_pie_chart(\n",
    "    model_categories_count.values(), \n",
    "    model_categories_count.keys(), \n",
    "    \"Results of RQ1: Issues Categorization via Trained Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question 2\n",
    "\n",
    "What is the typical structure of conversations between developers and ChatGPT?   \n",
    "How many turns does it take on average to reach a conclusion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_json_files_rq2():\n",
    "    structure = {\n",
    "        \"NumberOfPrompts\": [],\n",
    "        \"TokensOfPrompts\": [],\n",
    "        \"TokensOfAnswers\": [],\n",
    "        \"ListOfCode\": 0,\n",
    "        \"TotalConversations\": 0,\n",
    "    }\n",
    "  \n",
    "    for data in get_snapshots():\n",
    "        for source in data.get(\"Sources\", []):\n",
    "            chatgpt_sharing = source.get(\"ChatgptSharing\", [])\n",
    "            for sharing in chatgpt_sharing:\n",
    "                \n",
    "                number_of_prompts = sharing.get(\"NumberOfPrompts\")\n",
    "                if number_of_prompts is not None or \"\":\n",
    "                    structure[\"NumberOfPrompts\"].append(number_of_prompts)\n",
    "\n",
    "                number_of_tokens_per_prompts = sharing.get(\"TokensOfPrompts\")\n",
    "                if number_of_tokens_per_prompts is not None or \"\":\n",
    "                    structure[\"TokensOfPrompts\"].append(\n",
    "                        number_of_tokens_per_prompts\n",
    "                    )\n",
    "\n",
    "                number_of_tokens_per_answers = sharing.get(\"TokensOfAnswers\")\n",
    "                if number_of_tokens_per_answers is not None or \"\":\n",
    "                    structure[\"TokensOfAnswers\"].append(\n",
    "                        number_of_tokens_per_answers\n",
    "                    )\n",
    "\n",
    "                # Get number of conversations having code\n",
    "                for conversation in sharing.get(\"Conversations\", []):\n",
    "                    structure[\"TotalConversations\"] += 1\n",
    "                    list_of_code = conversation.get(\"ListOfCode\", [])\n",
    "                    if len(list_of_code) > 0:\n",
    "                        structure[\"ListOfCode\"] += 1\n",
    "\n",
    "    return structure\n",
    "\n",
    "\n",
    "print(\"Starting analysis...\")\n",
    "structure_results = process_json_files_rq2()\n",
    "print(\"\\nAnalysis completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RQ2 Results: Structure and statistics of conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results:\")\n",
    "\n",
    "print(\"\\tNumber of total conversations: \", structure_results[\"TotalConversations\"])\n",
    "print(\"\\tNumber of conversations having code: \", structure_results[\"ListOfCode\"])\n",
    "\n",
    "print(\n",
    "    \"\\tAverage number of prompts in a conversations: \",\n",
    "    calculate_average(structure_results[\"NumberOfPrompts\"]),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\tAverage number of words in a question of a conversation: \",\n",
    "    calculate_average(structure_results[\"TokensOfPrompts\"]),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"\\tAverage number of words in an answer of a conversation: \",\n",
    "    calculate_average(structure_results[\"TokensOfAnswers\"]),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
